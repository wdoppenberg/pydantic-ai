interactions:
- request:
    headers:
      accept:
      - application/json
      accept-encoding:
      - gzip, deflate
      connection:
      - keep-alive
      content-length:
      - '279'
      content-type:
      - application/json
      host:
      - api.openai.com
    method: POST
    parsed_body:
      messages:
      - content: What is the model name?
        role: user
      model: gpt-4o
      stream: false
      tool_choice: auto
      tools:
      - function:
          description: ''
          name: get_model_name
          parameters:
            additionalProperties: false
            properties: {}
            type: object
        type: function
    uri: https://api.openai.com/v1/chat/completions
  response:
    headers:
      access-control-expose-headers:
      - X-Request-ID
      alt-svc:
      - h3=":443"; ma=86400
      connection:
      - keep-alive
      content-length:
      - '1064'
      content-type:
      - application/json
      openai-organization:
      - pydantic-28gund
      openai-processing-ms:
      - '1141'
      openai-project:
      - proj_dKobscVY9YJxeEaDJen54e3d
      openai-version:
      - '2020-10-01'
      strict-transport-security:
      - max-age=31536000; includeSubDomains; preload
      transfer-encoding:
      - chunked
    parsed_body:
      choices:
      - finish_reason: tool_calls
        index: 0
        logprobs: null
        message:
          annotations: []
          content: null
          refusal: null
          role: assistant
          tool_calls:
          - function:
              arguments: '{}'
              name: get_model_name
            id: call_wB0C4FAOjxYgTNJrQT9NzzZ9
            type: function
      created: 1755036404
      id: chatcmpl-C3rQisW29iISecZ6NMn4FrseeO3A9
      model: gpt-4o-2024-08-06
      object: chat.completion
      service_tier: default
      system_fingerprint: fp_07871e2ad8
      usage:
        completion_tokens: 11
        completion_tokens_details:
          accepted_prediction_tokens: 0
          audio_tokens: 0
          reasoning_tokens: 0
          rejected_prediction_tokens: 0
        prompt_tokens: 38
        prompt_tokens_details:
          audio_tokens: 0
          cached_tokens: 0
        total_tokens: 49
    status:
      code: 200
      message: OK
version: 1
